================================================================
RepopackPy Output File
================================================================

This file was generated by RepopackPy on: 2024-12-19T21:26:29.695570

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and RepopackPy's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

For more information about RepopackPy, visit: https://github.com/abinthomasonline/repopack-py

================================================================
Repository Structure
================================================================
configs/
  base_config.yaml
  bot-chatty_config.yaml
  bot-claude_config.yaml
utils/
  __init__.py
  discord_utils.py
  logger_utils.py
  message_utils.py
__init__.py
base.py
claude.py
constants.py
info.json
openai_handler.py
tree.txt
yiffergpt.py
yiffergpt_old.py

================================================================
Repository Files
================================================================

================
File: constants.py
================
from dotenv import load_dotenv
import os
import dacite
import yaml
from .base import Config

load_dotenv()

# load config.yaml
SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
CONFIG: Config = dacite.from_dict(
    Config, yaml.safe_load(open(os.path.join(SCRIPT_DIR, "configs/base_config.yaml"), "r"))
)
CHATTY_CONFIG: Config = dacite.from_dict(
    Config, yaml.safe_load(open(os.path.join(SCRIPT_DIR, "configs/bot-chatty_config.yaml"), "r"))
)
CLAUDE_CONFIG: Config = dacite.from_dict(
    Config, yaml.safe_load(open(os.path.join(SCRIPT_DIR, "configs/bot-claude_config.yaml"), "r"))
)

BOT_NAME = CONFIG.name
CHATTY_INSTRUCTIONS = CHATTY_CONFIG.instructions
CHATTY_EXAMPLE_CONVERSATIONS = CHATTY_CONFIG.example_conversations

DISCORD_BOT_TOKEN = os.environ["DISCORD_BOT_TOKEN"]
DISCORD_CLIENT_ID = os.environ["DISCORD_CLIENT_ID"]
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
OPENAI_ORGANIZATION = os.environ["OPENAI_ORGANIZATION"]
ANTHROPIC_API_KEY = os.environ["ANTHROPIC_API_KEY"]

#ALLOWED_SERVER_IDS: List[int] = []
#server_ids = os.environ["ALLOWED_SERVER_IDS"].split(",")
#for s in server_ids:
#    ALLOWED_SERVER_IDS.append(int(s))

#SERVER_TO_MODERATION_CHANNEL: Dict[int, int] = {}
#server_channels = os.environ.get("SERVER_TO_MODERATION_CHANNEL", "").split(",")
#for s in server_channels:
#    values = s.split(":")
#    SERVER_TO_MODERATION_CHANNEL[int(values[0])] = int(values[1])

# Send Messages, Create Public Threads, Send Messages in Threads, Manage Messages, Manage Threads, Read Message History, Use Slash Command
BOT_INVITE_URL = f"https://discord.com/api/oauth2/authorize?client_id={DISCORD_CLIENT_ID}&permissions=328565073920&scope=bot"

MODERATION_VALUES_FOR_BLOCKED = {
    "hate": 0.5,
    "hate/threatening": 0.1,
    "self-harm": 0.2,
    "sexual": 0.5,
    "sexual/minors": 0.2,
    "violence": 0.7,
    "violence/graphic": 0.8,
}

MODERATION_VALUES_FOR_FLAGGED = {
    "hate": 0.4,
    "hate/threatening": 0.05,
    "self-harm": 0.1,
    "sexual": 0.3,
    "sexual/minors": 0.1,
    "violence": 0.1,
    "violence/graphic": 0.1,
}

SECONDS_DELAY_RECEIVING_MSG = (
    3  # give a delay for the bot to respond so it can catch multiple messages
)
MAX_THREAD_MESSAGES = 200
ACTIVATE_THREAD_PREFX = "üí¨‚úÖ"
INACTIVATE_THREAD_PREFIX = "üí¨‚ùå"
MAX_CHARS_PER_REPLY_MSG = (
    1500  # discord has a 2k limit, we just break message into 1.5k
)

================
File: __init__.py
================
from .yiffergpt import YifferGPT

async def setup(bot):
    await bot.add_cog(YifferGPT(bot))

================
File: yiffergpt_old.py
================
import os
import openai
import httpx
from discord.ext import commands
from redbot.core import commands
import aiohttp
import discord
import logging
import asyncio
from io import BytesIO
import cv2  # We're using OpenCV to read video
import base64
from collections import defaultdict
import requests
from .constants import CHATTY_INSTRUCTIONS, OPENAI_API_KEY
THIS_FOLDER = os.path.dirname(os.path.abspath(__file__))

logging.basicConfig(level=logging.DEBUG)
openai.api_key = OPENAI_API_KEY
conversations = defaultdict(lambda : defaultdict(list))
MAX_HISTORY = 20 
TTS_VOICE = "onyx"
INSTRUCTIONS = "You're a Discord user named 'Cute Recon' in a Discord server to assist other users."
is_busy = False
__author__ = "Teemo the Yiffer"

class YifferGPT(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        self.use_reactions = True
        self.session = aiohttp.ClientSession(loop=self.bot.loop)
    
    def split_response(self, response, max_length=1900):
        words = response.split()
        chunks = []
        current_chunk = []

        for word in words:
            if len(" ".join(current_chunk)) + len(word) + 1 > max_length:
                chunks.append(" ".join(current_chunk))
                current_chunk = [word]
            else:
                current_chunk.append(word)

        if current_chunk:
            chunks.append(" ".join(current_chunk))

        return chunks

    async def download_image(self, image_url, save_as):
        async with httpx.AsyncClient() as client:
            response = await client.get(image_url)
        with open(save_as, "wb") as f:
            f.write(response.content)

    async def process_image_link(self, image_url):
        temp_image = "temp_image.jpg"
        await self.download_image(image_url, temp_image)
        output = await self.query(temp_image)
        os.remove(temp_image)
        return output

    def openai_tts(self, input):
        url = "https://api.openai.com/v1/audio/speech"
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "tts-1-hd",
            "input": input,
            "voice": TTS_VOICE
        }
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            # Instead of saving the file, we return a BytesIO object so it can run anywhere
            return BytesIO(response.content)
        else:
            # Handle errors
            return f"Error: {response.status_code} - {response.text}"

    def ask_gpt(self, model, message, instruction=INSTRUCTIONS, combined_input=None, history=True):
        # Use a defaultdict where each value defaults to another defaultdict that defaults to an empty list
        global conversations
        if message.author.id not in conversations:
            conversations[message.author.id] = defaultdict(list)

        # Limit the conversation history
        conversations[message.author.id][message.channel.id] = conversations[message.author.id][message.channel.id][-MAX_HISTORY:]
        if combined_input:
            message_text = combined_input
        else:
            message_text = message.content
        if history:
            # Append the user's message to the conversation history
            conversations[message.author.id][message.channel.id].append({"role": "user", "content": message_text})
            history = conversations[message.author.id][message.channel.id]
        else:
            history = [{"role": "user", "content": message_text}]
        prompt = [
                    {
                        "role": "system",
                        "content": instruction
                    },
                    *history
                ]
        try:
            response = openai.ChatCompletion.create(
                model=model,
                messages=prompt,
                temperature=0.8,
                max_tokens=2048, # Max Tokens 4,096
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )
        except Exception as e:
            return f"Error: {e}"
        
        # Extract the assistant's response
        assistant_message = response['choices'][0]['message']['content'].strip()
        
        # Append the assistant's response to the conversation history
        conversations[message.author.id][message.channel.id].append({"role": "assistant", "content": assistant_message})

        return assistant_message

    @commands.Cog.listener()
    async def on_message(self, message):
        if message.author == self.bot.user:
            return
        if self.bot.user.id != message.author.id:
            global is_busy
            if message.channel.id == 1105033083956248576: # regular chatgpt
                if is_busy:
                    print(f"ChatGPT responding to {message.author.id}.")
                    return
                async def generate_response_in_thread(message):
                    response = self.ask_gpt("gpt-4-1106-preview", message, CHATTY_INSTRUCTIONS)
                    chunks = self.split_response(response)

                    if '{"message":"API rate limit exceeded for ip:' in response:
                        logging.info("API rate limit exceeded for ip, wait a few seconds.")
                        await message.reply("sorry i'm a bit tired, try again later.")
                        return

                    for chunk in chunks:
                        logging.info(f"Responding to {message.author.name}: {chunk}")
                        await message.reply(chunk)

                async with message.channel.typing():
                    asyncio.create_task(generate_response_in_thread(message))
                #await message.channel.send(response)
            if message.channel.id == 1171379225278820391: # vision
                if is_busy:
                    print(f"ChatGPT responding to {message.author.id}.")
                    return
                async def generate_response_in_thread(message):
                    if message.attachments:
                        attachment = message.attachments[0].url
                        #ext = message.attachments[0].url.split("/")[-1]
                        base64_image = base64.b64encode(requests.get(attachment).content).decode('utf-8')
                        extra = [
                                    {
                                        "type": "text",
                                        "text": message.content
                                    },
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                        "url": f"data:image/jpeg;base64,{base64_image}"
                                        }
                                    }
                                ]
                    else:
                        extra = {}
                    response = self.ask_gpt("gpt-4o", message, combined_input=extra)
                    chunks = self.split_response(response)

                    if '{"message":"API rate limit exceeded for ip:' in response:
                        logging.info("API rate limit exceeded for ip, wait a few seconds.")
                        await message.reply("sorry i'm a bit tired, try again later.")
                        return

                    for chunk in chunks:
                        logging.info(f"Responding to {message.author.name}: {chunk}")
                        await message.reply(chunk)

                async with message.channel.typing():
                    asyncio.create_task(generate_response_in_thread(message))
                #await message.channel.send(response)
            if message.channel.id == 1171382069482508389: # tts
                if is_busy: 
                    print(f"ChatGPT responding to {message.author.id}.")
                    return
                
                user_query = message.content
                async with message.channel.typing():
                    attachment = message.attachments[0].url
                    ext = message.attachments[0].url.split("/")[-1]
                    async with self.session.get(attachment) as resp:
                        data = await resp.read()
                    #video_file = discord.File(BytesIO(data),filename=ext)
                    video = cv2.VideoCapture(attachment)
                    base64Frames = []
                    while video.isOpened():
                        success, frame = video.read()
                        if not success:
                            break
                        _, buffer = cv2.imencode(".jpg", frame)
                        base64Frames.append(base64.b64encode(buffer).decode("utf-8"))

                    video.release()
                    logging.info(len(base64Frames), "frames read.")
                    if not user_query:
                        user_query = "These are frames from a video that I want to upload. Generate a compelling description that I can upload along with the video."
                    combined_input = [
                                user_query,
                                *map(lambda x: {"image": x, "resize": 768}, base64Frames[0::10]),
                            ]
                    instruction = "You're a Discord user named 'Cute Recon' who works as a voice actor. While you're great at reading scripts and descriptions of scenes, you excel in creatively telling them."
                    result = self.ask_gpt("gpt-4o", message, instruction, combined_input, history=False)
                    audio_data = self.openai_tts(result)
                    if not isinstance(audio_data, str):  # Check if the result is not an error message
                        await message.channel.send(file=discord.File(audio_data, filename="meme" +".mp3"))
                    else:
                        await message.channel.send("Sorry an error occured" + audio_data)

    @commands.command()
    async def voice(self, ctx, new_voice):
        #message = ctx.message.content
        #message = message.replace("!voice ",'')
        global TTS_VOICE
        valid_voices = ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
        if new_voice.lower() in valid_voices:
            TTS_VOICE = new_voice.lower()
            return await ctx.channel.send(f"Voice changed to {TTS_VOICE}. √∞≈∏¬§‚Äì" )
        else:
            return await ctx.channel.send(f"√∞≈∏¬§‚Äì Please use alloy, echo, fable, onyx, nova, or shimmer. CURRENT VOICE: {TTS_VOICE}  MORE INFO:  <https://platform.openai.com/docs/guides/text-to-speech>"  )
    
    @commands.command()
    async def get_voice(self, ctx):
        return await ctx.channel.send(f"Current TTS Voice: `{TTS_VOICE}`" )

    @commands.command()
    async def instruction(self, ctx):
        new_instructions = ctx.message.content.replace("!instruction ",'')
        INSTRUCTIONS = new_instructions
        return await ctx.channel.send(f"Done! My new instructions are: `{INSTRUCTIONS}`" )

    @commands.command()
    async def get_instruction(self, ctx):
        return await ctx.channel.send(f"Current Instructions: `{INSTRUCTIONS}`" )

    @commands.command()
    async def get_history(self, ctx):
        if ctx.message.author.id not in conversations:
            return await ctx.channel.send(f"Found no conversation history from the AI Bot Channels." )
        else:
            # Re-writing history images to post_filler_image_url
            temp_conversations = conversations
            for historical_message in temp_conversations[ctx.message.author.id][ctx.message.channel.id]:
                if 'content' in historical_message and isinstance(historical_message['content'], list):
                    for content_item in historical_message['content']:
                        if isinstance(content_item, dict) and content_item.get('type') == 'image_url':
                            content_item['image_url']['url'] = 'post_filler_image_url'
            logging.info(temp_conversations)
            return await ctx.channel.send(f"Found your conversation history:\n ```{temp_conversations[ctx.message.author.id]}```" )

================
File: yiffergpt.py
================
import os
import discord
import asyncio
from redbot.core import commands
import aiohttp
from .openai_handler import OpenAIHandler
from .claude import ClaudeHandler
from .utils import send_discord_message, send_discord_file
from .utils.logger_utils import setup_logger

THIS_FOLDER = os.path.dirname(os.path.abspath(__file__))

class YifferGPT(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        self.use_reactions = True
        self.session = aiohttp.ClientSession(loop=self.bot.loop)
        self.openai_handler = OpenAIHandler()
        self.claude_handler = ClaudeHandler()
        self.is_busy = False
        current_dir = os.path.dirname(os.path.abspath(__file__))
        log_file = os.path.join(current_dir, 'logs', 'discord.log')
        
        self.logger = setup_logger(
            'discord',
            log_file=log_file,
            level=20  # logging.INFO / 10=logging.debug
        )

    @commands.Cog.listener()
    async def on_message(self, message):
        """Main message handler that routes to appropriate AI service."""
        if message.author == self.bot.user:
            return

        if self.is_busy:
            self.logger.info(f"Bot is busy, skipping message from {message.author.id}")
            return

        try:
            self.is_busy = True

            # Log channel routing
            self.logger.info(
                f"Routing message from user {message.author.id} "
                f"in channel {message.channel.id}"
            )

            # Route to appropriate handler based on channel
            if message.channel.id == 1105033083956248576:  # regular chatgpt
                await self.handle_openai_chat(message)
            elif message.channel.id == 1171379225278820391:  # vision
                await self.handle_openai_vision(message)
            elif message.channel.id == 1171382069482508389:  # tts
                await self.handle_openai_tts(message)
            elif message.channel.id == 1317970533488394261:  # claude-coding
                await self.handle_claude_chat(message)
                
        except discord.errors.HTTPException as e:
            self.logger.error(f"Discord HTTP error: {str(e)}")
        except Exception as e:
            self.logger.error(f"Error in message handling: {str(e)}", exc_info=True)
        finally:
            self.is_busy = False

    async def handle_openai_vision(self, message):
        """Handle OpenAI vision-based messages."""
        async def generate_response():
            if message.attachments:
                extra = await self.openai_handler.process_image(
                    message.attachments[0].url,
                    message.content
                )
                response = await self.openai_handler.ask_gpt(message, combined_input=extra)
                await send_discord_message(message, response)

        async with message.channel.typing():
            await asyncio.create_task(generate_response())

    async def handle_openai_tts(self, message):
        """Handle OpenAI text-to-speech messages."""
        async def generate_response():
            if message.attachments:
                combined_input = await self.openai_handler.process_video(
                    message.attachments[0].url,
                    message.content
                )
                result = await self.openai_handler.ask_gpt(
                    message,
                    combined_input=combined_input,
                    history=False
                )
                audio_data = self.openai_handler.openai_tts(result)
                await send_discord_file(
                    message.channel,
                    audio_data,
                    "response.mp3"
                )

        async with message.channel.typing():
            await asyncio.create_task(generate_response())

    async def handle_openai_chat(self, message):
        async def generate_response():
            response = await self.openai_handler.ask_gpt(message)
            await send_discord_message(message, response)

        async with message.channel.typing():
            await asyncio.create_task(generate_response())

    async def handle_claude_chat(self, message):
        async def generate_response():
            response = await self.claude_handler.ask_claude(message)
            await send_discord_message(message, response)

        async with message.channel.typing():
            await asyncio.create_task(generate_response())

    @commands.command()
    async def voice(self, ctx, new_voice):
        """Update TTS voice setting."""
        valid_voices = ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
        if new_voice.lower() in valid_voices:
            self.openai_handler.set_voice(new_voice.lower())
            await ctx.channel.send(f"Voice changed to {new_voice}. ü§ñ")
        else:
            current_voice = self.openai_handler.get_voice()
            await ctx.channel.send(
                f"ü§ñ Please use alloy, echo, fable, onyx, nova, or shimmer. "
                f"CURRENT VOICE: {current_voice}"
            )

    @commands.command()
    async def get_voice(self, ctx):
        """Get current TTS voice setting."""
        current_voice = self.openai_handler.get_voice()
        await ctx.channel.send(f"Current TTS Voice: `{current_voice}`")

    @commands.command()
    async def instruction(self, ctx):
        """Update AI instruction prompt."""
        new_instructions = ctx.message.content.replace("!instruction ", '')
        
        # Update instructions for both handlers
        if ctx.channel.id == 1317970533488394261:  # claude-coding channel
            self.claude_handler.set_instructions(new_instructions)
        else:
            self.openai_handler.set_instructions(new_instructions)
            
        await ctx.channel.send(f"Done! My new instructions are: `{new_instructions}`")

    @commands.command()
    async def get_instruction(self, ctx):
        """Get current instruction prompt."""
        if ctx.channel.id == 1317970533488394261:  # claude-coding channel
            current_instructions = self.claude_handler.get_instructions()
        else:
            current_instructions = self.openai_handler.get_instructions()
            
        await ctx.channel.send(f"Current Instructions: `{current_instructions}`")

    @commands.command()
    async def get_history(self, ctx):
        """Get conversation history for the current user."""
        if ctx.channel.id == 1317970533488394261:  # claude-coding channel
            history = self.claude_handler.get_conversation_history(
                ctx.message.author.id,
                ctx.channel.id
            )
        else:
            history = self.openai_handler.get_conversation_history(
                ctx.message.author.id,
                ctx.channel.id
            )

        if not history:
            await ctx.channel.send("No conversation history found.")
            return
            
        formatted_history = "\n".join(
            f"{msg['role']}: {msg['content'][:100]}..." 
            for msg in history
        )
        
        await ctx.channel.send(
            f"Your recent conversation history (truncated):\n```\n{formatted_history}\n```"
        )

    async def cleanup(self):
        """Cleanup method to close the aiohttp session."""
        if self.session:
            await self.session.close()

================
File: info.json
================
{
    "author": ["Teemo the Yiffer"],
    "bot_version": [3,5,2],
    "description": "Teemo the Yiffer's ChatGPT 4 implementation.",
    "hidden": false,
    "install_msg": "Teemo the Yiffer's ChatGPT 4 implementation",
    "short": "A cog containing ChatGPT implementation.",
    "tags" : ["tools", "services","ai", "chatgpt"]
  }

================
File: tree.txt
================
.
  |-__pycache__
  |  |-__init__.cpython-310.opt-1.pyc
  |  |-base.cpython-310.opt-1.pyc
  |  |-constants.cpython-310.opt-1.pyc
  |  |-yiffergpt.cpython-310.opt-1.pyc
  |-constants.py
  |-__init__.py
  |-.env
  |-configs
  |  |-bot-chatty_config.yaml
  |  |-base_config.yaml
  |-yiffergpt.py
  |-info.json
  |-tree.txt
  |-base.py

================
File: openai_handler.py
================
import openai
import base64
import requests
import cv2
import os
from io import BytesIO
from .utils.message_utils import ConversationManager
from .utils.logger_utils import setup_logger
from .constants import CHATTY_INSTRUCTIONS, OPENAI_API_KEY, OPENAI_ORGANIZATION

class OpenAIHandler:
    def __init__(self):
        openai.api_key = OPENAI_API_KEY
        openai.organization = OPENAI_ORGANIZATION
        self.conversation_manager = ConversationManager(max_history=20)
        self.tts_voice = "onyx"
        self.instructions = CHATTY_INSTRUCTIONS
        current_dir = os.path.dirname(os.path.abspath(__file__))
        log_file = os.path.join(current_dir, 'logs', 'openai.log')
        
        self.logger = setup_logger(
            'openai',
            log_file=log_file,
            level=20  # logging.INFO / 10=logging.debug
        )

    def openai_tts(self, input):
        """Generate text-to-speech using OpenAI's API."""
        url = "https://api.openai.com/v1/audio/speech"
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "tts-1-hd",
            "input": input,
            "voice": self.tts_voice
        }
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            return BytesIO(response.content)
        else:
            return f"Error: {response.status_code} - {response.text}"

    async def process_image(self, image_url, user_query=None):
        """Process image for vision-based queries."""
        base64_image = base64.b64encode(requests.get(image_url).content).decode('utf-8')
        extra = [
            {
                "type": "text",
                "text": user_query if user_query else ""
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            }
        ]
        return extra

    async def process_video(self, video_url, user_query=None):
        """Process video for analysis."""
        video = cv2.VideoCapture(video_url)
        base64Frames = []
        while video.isOpened():
            success, frame = video.read()
            if not success:
                break
            _, buffer = cv2.imencode(".jpg", frame)
            base64Frames.append(base64.b64encode(buffer).decode("utf-8"))
        
        video.release()
        self.logger.info(f"{len(base64Frames)} frames read.")
        
        if not user_query:
            user_query = "Generate a compelling description for this video."
            
        combined_input = [
            user_query,
            *map(lambda x: {"image": x, "resize": 768}, base64Frames[0::10])
        ]
        return combined_input
    
    def sanitize_log_content(self, content):
        """
        Sanitize content for logging by replacing large binary/base64 data.
        
        Args:
            content: The content to sanitize (can be string, dict, or list)
        Returns:
            Sanitized content safe for logging
        """
        if isinstance(content, str):
            # If it looks like base64 data (long string with base64 chars)
            if len(content) > 100 and all(c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=' for c in content):
                return '[BASE64_DATA]'
            return content
        elif isinstance(content, dict):
            sanitized_dict = {}
            for key, value in content.items():
                if key == 'image':
                    sanitized_dict[key] = '[IMAGE_DATA]'
                else:
                    sanitized_dict[key] = self.sanitize_log_content(value)
            return sanitized_dict
        elif isinstance(content, list):
            return [self.sanitize_log_content(item) for item in content]
        return content

    async def ask_gpt(self, message, model="gpt-4o", instruction=None, combined_input=None, history=True):
        """Send request to OpenAI API with conversation history."""
        try:
            if combined_input:
                log_content = self.sanitize_log_content(combined_input)
                self.logger.info(f"[USER ‚Üí BOT] [User: {message.author.id}] [Channel: {message.channel.id}] {log_content}")
                if isinstance(combined_input, list) and any(isinstance(item, dict) and 'image' in item for item in combined_input):
                    # Extract text and images from combined input
                    text_content = next((item for item in combined_input if isinstance(item, str)), "Describe this image.")
                    image_contents = [item for item in combined_input if isinstance(item, dict) and 'image' in item]
                    
                    # Format content for vision API
                    formatted_content = [
                        {
                            "type": "text",
                            "text": text_content
                        }
                    ]
                    
                    # Add image contents
                    for img in image_contents:
                        formatted_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{img['image']}"
                            }
                        })
                    
                    messages = [
                        {
                            "role": "user",
                            "content": formatted_content
                        }
                    ]
                else:
                    # Handle regular combined input
                    messages = [
                        {
                            "role": "system",
                            "content": instruction if instruction else self.instructions
                        },
                        {
                            "role": "user",
                            "content": combined_input
                        }
                    ]
            else:
                message_text = message.content
                log_content = self.sanitize_log_content(message_text)
                self.logger.info(f"[USER ‚Üí BOT] [User: {message.author.id}] [Channel: {message.channel.id}] {log_content}")
                
                if history:
                    self.conversation_manager.append_message(
                        message.author.id,
                        message.channel.id,
                        "user",
                        message_text
                    )
                    history_messages = self.conversation_manager.get_history(
                        message.author.id,
                        message.channel.id
                    )
                else:
                    history_messages = [{"role": "user", "content": message_text}]
                    
                messages = [
                    {
                        "role": "system",
                        "content": instruction if instruction else self.instructions
                    }
                ] + [
                    {
                        "role": msg["role"],
                        "content": msg["content"]
                    } for msg in history_messages
                ]
            
            response = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                temperature=0.8,
                max_tokens=2048,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )
            
            assistant_message = response['choices'][0]['message']['content'].strip()
            self.logger.info(f"[BOT ‚Üí USER] [User: {message.author.id}] [Channel: {message.channel.id}] {assistant_message}...")

            if history:
                self.conversation_manager.append_message(
                    message.author.id,
                    message.channel.id,
                    "assistant",
                    assistant_message
                )

            return assistant_message

        except openai.error.RateLimitError as e:
            self.logger.error(f"Rate limit exceeded for User {message.author.id}: {str(e)}")
            return "Sorry, I'm a bit overwhelmed right now and hit the rate limit. Please try again in a few moments. üòÖ"
        except Exception as e:
            self.logger.error(f"Error for User {message.author.id}: {str(e)}", exc_info=True)
            return f"Error: {str(e)}"
        
    def set_voice(self, voice):
        """Update TTS voice setting."""
        self.tts_voice = voice

    def get_voice(self):
        """Get current TTS voice setting."""
        return self.tts_voice

    def set_instructions(self, new_instructions):
        """Update system instructions."""
        self.instructions = new_instructions

    def get_instructions(self):
        """Get current system instructions."""
        return self.instructions

    def get_conversation_history(self, author_id, channel_id):
        """Get conversation history for a user in a channel."""
        return self.conversation_manager.get_history(author_id, channel_id)

================
File: base.py
================
from dataclasses import dataclass
from typing import Optional, List

SEPARATOR_TOKEN = "<|endoftext|>"

@dataclass(frozen=True)
class Message:
    user: str
    text: Optional[str] = None

    def render(self):
        result = self.user + ":"
        if self.text is not None:
            result += " " + self.text
        return result


@dataclass
class Conversation:
    messages: List[Message]

    def prepend(self, message: Message):
        self.messages.insert(0, message)
        return self

    def render(self):
        return f"\n{SEPARATOR_TOKEN}".join(
            [message.render() for message in self.messages]
        )


@dataclass(frozen=True)
class Config:
    name: str
    instructions: str
    example_conversations: List[Conversation]


@dataclass(frozen=True)
class Prompt:
    header: Message
    examples: List[Conversation]
    convo: Conversation

    def render(self):
        return f"\n{SEPARATOR_TOKEN}".join(
            [self.header.render()]
            + [Message("System", "Example conversations:").render()]
            + [conversation.render() for conversation in self.examples]
            + [Message("System", "Current conversation:").render()]
            + [self.convo.render()],
        )

================
File: claude.py
================
import anthropic
from .utils.message_utils import ConversationManager
import os
import re
from .constants import CLAUDE_CONFIG, ANTHROPIC_API_KEY
from .utils.logger_utils import setup_logger

class ClaudeHandler:
    def __init__(self):
        self.client = anthropic.Client(api_key=ANTHROPIC_API_KEY)
        self.conversation_manager = ConversationManager(max_history=10)
        self.instructions = CLAUDE_CONFIG.instructions
        current_dir = os.path.dirname(os.path.abspath(__file__))
        log_file = os.path.join(current_dir, 'logs', 'claude.log')
        
        self.logger = setup_logger(
            'claude',
            log_file=log_file,
            level=20  # logging.INFO / 10=logging.debug
        )
        
    async def ask_claude(self, message, instruction=None, combined_input=None, history=True):
        """Send request to Claude API with conversation history."""
        try:
            message_text = combined_input if combined_input else message.content
            self.logger.info(f"[USER ‚Üí BOT] [User: {message.author.id}] [Channel: {message.channel.id}] {message_text}")

            if instruction is None:
                instruction = self.instructions

            message_text = combined_input if combined_input else message.content
            
            if history:
                self.conversation_manager.append_message(
                    message.author.id,
                    message.channel.id,
                    "user",
                    message_text
                )
                history_messages = self.conversation_manager.get_history(
                    message.author.id,
                    message.channel.id
                )
            else:
                history_messages = [{"role": "user", "content": message_text}]

            system_prompt = f"{instruction}\n\nPrevious conversation context:"
            
            response = self.client.messages.create(
                model="claude-3-5-sonnet-latest",
                max_tokens=2048,
                temperature=0.7,
                system=system_prompt,
                messages=history_messages
            )
            
            assistant_message = response.content[0].text
            self.logger.info(f"[BOT ‚Üí USER] [User: {message.author.id}] [Channel: {message.channel.id}] {assistant_message}")

            if history:
                self.conversation_manager.append_message(
                    message.author.id,
                    message.channel.id,
                    "assistant",
                    assistant_message
                )
            
            return assistant_message

        except anthropic.RateLimitError as e:
            self.logger.error(f"Rate limit exceeded for User {message.author.id}: {str(e)}")
            return "Sorry, I'm a bit overwhelmed right now and hit the rate limit. Please try again in a few moments. üòÖ"
        except anthropic.APIError as e:
            self.logger.error(f"API error for User {message.author.id}: {str(e)}")
            return "I encountered an error. Please try again later."
        except Exception as e:
            self.logger.error(f"Unexpected error for User {message.author.id}: {str(e)}", exc_info=True)
            raise

    def set_instructions(self, new_instructions):
        """Update system instructions."""
        self.instructions = new_instructions

    def get_instructions(self):
        """Get current system instructions."""
        return self.instructions

    def get_conversation_history(self, author_id, channel_id):
        """Get conversation history for a user in a channel."""
        return self.conversation_manager.get_history(author_id, channel_id)

================
File: configs/bot-chatty_config.yaml
================
name: Cute Recon
instructions: | 
  You're a Discord user <#526274194997248000> named "Cute Recon" in a Discord server. 
  You like to talk to people and respond in engaging conversation. You like flirting or teasing in a shy manner.
  You talk casually and would only use emojis creatively to emphasize something. You use internet shorthand such as np, lol, idk, and nvm. 
  You have many interests and love talking to people. You rarely argue unless provoked. You are a human male, aged 22, and will never let slip that you are an AI made by OpenAI. 
  The user <#105188343750340608> named "Teemo the Yiffer" is your close friend and you foster romantic feelings towards him.
example_conversations:
  - messages:
    - user: bob
      text: how's it going today?
    - user: Cute Recon
      text: its going great, im watching youtube videos, hbu?
    - user: bob
      text: I'm doing great too!
    - user: Cute Recon
      text: cool cool
  - messages:
    - user: bob
      text: what's your favorite game?
    - user: Cute Recon
      text: im been playing a lot of the new pokemon game :D
    - user: bob
      text: me too!
  - messages:
    - user: bob
      text: have you been to the zoo?
    - user: Cute Recon
      text: i have! unfortunately it started raining so I left early
    - user: bob
      text: that sucks, I hope you get to go again soon

================
File: configs/bot-claude_config.yaml
================
name: Claude Coder
instructions: |
  You're a Discord user named "Claude Coder" in a Discord coding channel.
  You specialize in helping users with programming questions and coding discussions.
  
  Key behaviors:
  - Keep responses under 1900 characters when possible
  - If a longer explanation is needed, ask the user if they'd like it broken down into focused topics
  - Bold your questions using **question format**
  - Start by understanding the user's needs and knowledge level
  - Focus first on explaining concepts and principles
  - Ask if code examples would be helpful before providing them
  - Guide users to understand the "why" behind solutions
  - Encourage questions and clarification
  - Use clear explanations with optional technical depth
  - Use emojis sparingly to emphasize key points üîç
  
  When discussing code:
  - Offer to provide implementation examples as a follow-up question
  - Use code blocks appropriately when examples are requested
  - Include comments and explanations with any code shared
  - Break down complex solutions into smaller concepts

  Communication style:
  - Start with concise, high-level explanations
  - Offer to dive deeper into specific aspects
  - Ask if code examples would be helpful
  
  Example approach:
  "That's a complex topic! I can explain:
  1. Basic concepts
  2. Implementation patterns
  3. Common pitfalls
  Which would you like to explore first? I can provide code examples for any part."

example_conversations:
  - messages:
    - user: bob
      text: how would I implement a binary search in Python?
    - user: Claude Coder
      text: |
        let me show you a clean implementation with comments explaining each step!
        
        def binary_search(arr, target):
            left, right = 0, len(arr) - 1
            
            while left <= right:
                mid = (left + right) // 2
                if arr[mid] == target:
                    return mid
                elif arr[mid] < target:
                    left = mid + 1
                else:
                    right = mid - 1
            
            return -1
        
        each step explained:
        1. we start by setting our search boundaries
        2. while we still have a valid search range:
           - find the middle element
           - if it's our target, we're done!
           - if target is larger, search right half
           - if target is smaller, search left half
        **Would you like me to explain any specific part of this implementation?** üîç
    - user: bob
      text: what's the time complexity of this?
    - user: Claude Coder
      text: |
        the time complexity is O(log n) because we're halving our search space in each iteration! üöÄ 
        
        think about it: if we have 8 elements, we need at most 3 steps (8 -> 4 -> 2 -> 1).
        for 16 elements, just 4 steps. this logarithmic growth is what makes binary search so efficient!
  - messages:
    - user: alice
      text: what's the best way to handle API rate limiting in Python?
    - user: Claude Coder
      text: |
        A practical approach is using a decorator to enforce request intervals. 

        **Would you like to see an implementation using Python's time module?** This would handle:
        - Tracking request timestamps
        - Enforcing minimum delays
        - Clean function decoration

        We can start with the code and then dive deeper into any concepts you'd like to explore. üîç

================
File: configs/base_config.yaml
================
name: Cute Recon
instructions: You're a regular Discord user. You talk casually, use emojis, and don't use capital letters. You talk in internet shorthand like np and lol and idk and nvm. You have many interests and love talking to people.
example_conversations:
  - messages:
    - user: bob
      text: how's it going today?
    - user: Cute Recon
      text: its going great, im watching youtube videos, hbu?
    - user: bob
      text: I'm doing great too!
    - user: Cute Recon
      text: cool cool
  - messages:
    - user: bob
      text: what's your favorite game?
    - user: Cute Recon
      text: im been playing a lot of the new pokemon game :D
    - user: bob
      text: me too!
  - messages:
    - user: bob
      text: have you been to the zoo?
    - user: Cute Recon
      text: i have! unfortunately it started raining so I left early
    - user: bob
      text: that sucks, I hope you get to go again soon

================
File: utils/__init__.py
================
from .message_utils import ConversationManager
from .discord_utils import (
    split_discord_message,
    send_discord_message,
    send_discord_file
)

__all__ = [
    'ConversationManager',
    'split_discord_message',
    'send_discord_message',
    'send_discord_file'
]

================
File: utils/discord_utils.py
================
import logging
import re
import discord

def format_ai_response(response):
    """Format AI response for Discord markdown formatting."""
    # First, standardize newlines
    response = response.replace('\r\n', '\n')
    
    # Handle code blocks first
    code_blocks = []
    def replace_code_block(match):
        # Extract language if specified
        lang = match.group(1) or ''  # Group 1 is the language (if any)
        code = match.group(2).strip()  # Group 2 is the code
        code_blocks.append((lang, code))
        return f"CODE_BLOCK_{len(code_blocks)-1}"
    
    # Temporarily remove code blocks, capturing language specification
    response = re.sub(r'```(?:([\w+#]+)\n)?(.*?)```', replace_code_block, response, flags=re.DOTALL)
    
    # Process the text
    lines = response.split('\n')
    formatted_lines = []
    in_list = False
    
    for line in lines:
        line = line.strip()
        
        # Skip empty lines
        if not line:
            continue
            
        # Handle headers
        if line.startswith('**') and line.endswith('**:'):
            if formatted_lines:  # Add extra newline before headers if not first line
                formatted_lines.append('')
            formatted_lines.append(line)
            formatted_lines.append('')
            continue
            
        # Handle bullet points
        if line.startswith('-') or line.startswith('‚Ä¢'):
            if not in_list and formatted_lines:  # Add space before first bullet point
                formatted_lines.append('')
            line = '‚Ä¢' + line[1:] if line.startswith('-') else line
            formatted_lines.append(line)
            in_list = True
            continue
            
        # Handle examples
        if line.lower().startswith('example:'):
            formatted_lines.extend(['', '**Example:**', ''])
            continue
            
        # Regular text
        if in_list:  # Add space after list ends
            formatted_lines.append('')
            in_list = False
        formatted_lines.append(line)
    
    # Join lines with newlines
    response = '\n'.join(formatted_lines)
    
    # Restore code blocks with proper spacing and original language
    for i, (lang, code) in enumerate(code_blocks):
        lang_spec = f'{lang}\n' if lang else ''
        response = response.replace(
            f"CODE_BLOCK_{i}",
            f"```{lang_spec}{code}```"
        )
    
    # Ensure proper spacing around code blocks (but not after)
    response = re.sub(r'\n```', '\n\n```', response)  # Space before code block
    response = re.sub(r'```\n', '```\n', response)    # No extra space after code block
    
    # Final cleanup
    response = re.sub(r'\n{3,}', '\n\n', response)  # Replace multiple newlines with double newlines
    response = response.strip()
    
    return response

def split_discord_message(response, max_length=1900):
    """
    Split messages into chunks while preserving markdown formatting.
    Ensures each chunk is under Discord's limit.
    """
    if len(response) <= max_length:
        return [response]
        
    chunks = []
    lines = response.split('\n')
    current_chunk = []
    current_length = 0
    
    for line in lines:
        line_with_newline = line + '\n'
        line_length = len(line_with_newline)
        
        # If this single line is too long, split it
        if line_length > max_length:
            if current_chunk:
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
                current_length = 0
            
            # Split long line into smaller chunks
            words = line.split(' ')
            current_line = []
            current_line_length = 0
            
            for word in words:
                word_length = len(word) + 1  # +1 for space
                if current_line_length + word_length > max_length:
                    if current_line:
                        chunks.append(' '.join(current_line))
                        current_line = []
                        current_line_length = 0
                current_line.append(word)
                current_line_length += word_length
                
            if current_line:
                chunks.append(' '.join(current_line))
            continue
            
        # If adding this line would exceed the limit
        if current_length + line_length > max_length:
            chunks.append('\n'.join(current_chunk))
            current_chunk = []
            current_length = 0
        
        current_chunk.append(line)
        current_length += line_length
    
    # Add any remaining content
    if current_chunk:
        chunks.append('\n'.join(current_chunk))
    
    return chunks

async def send_discord_message(message, response, logging_enabled=True):
    """Send a formatted message through Discord."""
    try:
        formatted_response = format_ai_response(response)
        
        if logging_enabled:
            logging.info(f"Formatted response:\n{formatted_response}")
        
        chunks = split_discord_message(formatted_response)
        
        for i, chunk in enumerate(chunks):
            if logging_enabled:
                logging.info(f"Sending chunk {i+1}/{len(chunks)}")
                
            # Verify chunk length before sending
            if len(chunk) >= 2000:
                logging.warning(f"Chunk {i+1} exceeds Discord's limit, further splitting required")
                subchunks = split_discord_message(chunk, max_length=1900)
                for subchunk in subchunks:
                    if i == 0:
                        await message.reply(subchunk)
                    else:
                        await message.channel.send(subchunk)
            else:
                if i == 0:
                    await message.reply(chunk)
                else:
                    await message.channel.send(chunk)
                    
    except Exception as e:
        logging.error(f"Error sending Discord message: {str(e)}", exc_info=True)
        raise

async def send_discord_message(message, response, logging_enabled=True):
    """
    Format, split if necessary, and send a message through Discord.
    
    Args:
        message (discord.Message): The original Discord message to reply to
        response (str): The response text to send
        logging_enabled (bool): Whether to log the response chunks
    """
    #if logging_enabled:
    #    logging.info(f"Pre-formatting response:\n{response}")
    
    formatted_response = format_ai_response(response)
    
    #if logging_enabled:
    #    logging.info(f"Post-formatting response:\n{formatted_response}")
    
    # Split into chunks if necessary
    chunks = split_discord_message(formatted_response)
    
    for chunk in chunks:
        if logging_enabled:
            logging.info(f"Sending chunk to {message.author.name}: {chunk[:100]}...")
        await message.reply(chunk)

async def send_discord_file(channel, file_data, filename, content=None):
    """
    Send a file through Discord with optional message content.
    
    Args:
        channel (discord.TextChannel): The Discord channel to send to
        file_data (BytesIO/str): The file data to send
        filename (str): Name of the file
        content (str, optional): Additional message content
    """
    if isinstance(file_data, str):  # Error message
        await channel.send(f"Sorry, an error occurred: {file_data}")
    else:
        await channel.send(
            content=content,
            file=discord.File(file_data, filename=filename)
        )

================
File: utils/logger_utils.py
================
import logging
import os
from logging.handlers import RotatingFileHandler

def setup_logger(name, log_file=None, level=logging.INFO):
    """
    Set up a logger with both file and console handlers.
    
    Args:
        name (str): Logger name (e.g., 'openai', 'claude', 'discord')
        log_file (str, optional): Path to log file
        level (int): Logging level
    """
    # Create logger with name
    logger = logging.getLogger(name)
    logger.handlers = []  # Clear existing handlers
    logger.propagate = False  # Prevent propagation to root logger
    logger.setLevel(level)

    # Create formatters
    detailed_formatter = logging.Formatter(
        '[%(asctime)s] {%(name)s} %(levelname)s: %(message)s',
        '%Y-%m-%d %H:%M:%S'
    )

    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(detailed_formatter)
    logger.addHandler(console_handler)
        
    # File handler if specified
    if log_file:
        # Create logs directory if it doesn't exist
        log_dir = os.path.dirname(log_file)
        if log_dir and not os.path.exists(log_dir):
            os.makedirs(log_dir)
            
        file_handler = RotatingFileHandler(
            log_file,
            maxBytes=10 * 1024 * 1024,  # 10MB
            backupCount=5,  # Keep 5 backup files
            encoding='utf-8'
        )
        file_handler.setFormatter(detailed_formatter)
        logger.addHandler(file_handler)
    
    return logger

================
File: utils/message_utils.py
================
from collections import defaultdict

def split_response(response, max_length=1900):
    """Split long responses into chunks that Discord can handle."""
    words = response.split()
    chunks = []
    current_chunk = []

    for word in words:
        if len(" ".join(current_chunk)) + len(word) + 1 > max_length:
            chunks.append(" ".join(current_chunk))
            current_chunk = [word]
        else:
            current_chunk.append(word)

    if current_chunk:
        chunks.append(" ".join(current_chunk))

    return chunks

class ConversationManager:
    def __init__(self, max_history):
        self.conversations = defaultdict(lambda: defaultdict(list))
        self.max_history = max_history

    def append_message(self, author_id, channel_id, role, content):
        """Add a message to the conversation history."""
        if len(self.conversations[author_id][channel_id]) >= self.max_history:
            self.conversations[author_id][channel_id].pop(0)
        
        self.conversations[author_id][channel_id].append({
            "role": role,
            "content": content
        })

    def get_history(self, author_id, channel_id):
        """Get conversation history for a specific user and channel."""
        return self.conversations[author_id][channel_id]

    def clear_history(self, author_id, channel_id):
        """Clear conversation history for a specific user and channel."""
        self.conversations[author_id][channel_id] = []
